//This is the main file - you'll want to compile using this file (it imports every other one).

import 'pathfinder.del';
import 'customGameSettings.json';

globalvar define e = 2.718281828;
playervar define deltaReward = 0;
globalvar define choiceMaxSteps = 2;
globalvar define choiceStepSize = 7;
globalvar define deltaTime = 0;
globalvar define pastInputs = [];
globalvar define pastInputTimes = [];
globalvar define pastInputRewards = [];
globalvar define aiTime = 0;
playervar define aimTarget = null;
playervar define extraAction = null;
playervar define positionTracking = [];
globalvar define team1Score = 0;
globalvar define team2Score = 0;
playervar define dmgPercent; //dmg multiplier (in percent) for primary fire (compensating for near-perfect aim)
rule: 'assignDmgPercent'
Event.OngoingPlayer
{
    if (IsDummyBot(EventPlayer())) {
        dmgPercent = 30;
    } else {
        dmgPercent = 100;
    }
}

globalvar define players = [];
playervar define dmgDealtStat = 0;
playervar define healingStat = 0;
playervar define eliminationStat = 0;
playervar define deathStat = 0;
playervar define rocketDmgStat = 0;
playervar define ultimateDmgStat = 0;
playervar define healingLocation;

globalvar define w1Import1;
globalvar define w1Import2;
globalvar define w1Import3;
globalvar define w2Import;

rule: '>>> Import Weights Part 1 (paste them here!) <<<'
{
    
}

rule: '>>> Import Weights Part 2 (paste them here!) <<<'
{
    
}

rule: '>>> Import Weights Part 3 (paste them here!) <<<'
{
    
}

rule: 'init weights'
{
    Wait(5);
    w1 = [];
    w2 = [];
    if (w1Import1 != null && w1Import2 != null && w2Import != null) {
        w1 = Append(w1, w1Import1);
        w1 = Append(w1, w1Import2);
        w1 = Append(w1, w1Import3);
        w2 = w2Import;
    }
    else {
        //PLEASE ADJUST FOR ACTUAL NODE/WEIGHT COUNT AS NECESSARY
        for (define i = 0; i < 38; i++) {
            define array = [];
            for (define j! = 0; j < 10; j++) {
                array = Append(array, RandomReal(-1, 1));
            }   
            w1 = Append(w1, [array]);
            Wait(0.016);
        }

        for (define i = 0; i < 10; i++) {
            w2 = Append(w2, RandomReal(-1, 1));
        }
    }
}



//===============================================================================================================
//NEURAL NETWORK BEGINS HERE
//this could be bundled into a class, but classes are merely an abstraction that place their instance's vars into a shared array
//this effectively makes the weights a 3d array, which would kill performance
globalvar define learningRate = 0.001;
globalvar define w1;
globalvar define w2;   
globalvar define lastLayer1;

Number feedForward(define inputs) 'feed-forward'
{
    LogToInspector("Feeding forward...");
    define output = 0;
    define layer1 = [];

    //forward all inputs to hidden layer. w2 has one weight per HL node, so it's used for the countof
    for (define i = 0; i < CountOf(w2); i++) {
        for (define j = 0; j < CountOf(inputs); j++) {
            layer1[i] += inputs[j] * w1[j][i];
            //LogToInspector(w1[j][i]);
        }
    }
    //LogToInspector(layer1);

    Wait(0.016);

    //activation function on hidden layer
    for (define i = 0; i < CountOf(w2); i++) {
        layer1[i] = tanh(layer1[i]);
    } 

    //LogToInspector(layer1);

    //forward hidden layer to output node
    for (define i = 0; i < CountOf(w2); i++) {
        output += layer1[i] * w2[i];
    }

    lastLayer1 = layer1;

    return output;
}

//feedforward optimised for multiple FFs. calculates the non-activated values for the first hidden layer once,
//then reuses them for each FF, adding on inputs from extraInputs[i] each time.
//this reduces the multiplications needed for subsequent FFs, saving server resources
define optimisedFeedForward(define inputs, define extraInputs) 'optimised feed-forward' {
    define layer1 = [];
    define baseWeightI = 0;

    for (define i = 0; i < CountOf(w2); i++) {
        for (define j = 0; j < CountOf(inputs); j++) {
            layer1[i] += inputs[j] * w1[j][i];
            baseWeightI = j;
        }
    }

    Wait(0.016);
    //LogToInspector("i {0}".Format([baseWeightI]));

    define outputs = [];
    baseWeightI += 1;
    define breakI1 = RoundToInteger(CountOf(extraInputs) / 2);
    LogToInspector('the layers');
    for (define i = 0; i < CountOf(extraInputs); i++) {
        define output = 0;
        define hiddenLayer = layer1;
        define extraInput = extraInputs[i];
        for (define j = 0; j < CountOf(hiddenLayer); j++) {
            for (define k = 0; k < CountOf(extraInput); k++) {
                hiddenLayer[j] += extraInput[k] * w1[baseWeightI + k][j];
                //LogToInspector('multiplying {0} by {1}'.Format([extraInputs[i][k], w1[baseWeightI + 1 + k][j]]));
            }
        }

        for (define j = 0; j < CountOf(layer1); j++) {
            hiddenLayer[j] = tanh(hiddenLayer[j]);
        } 

        //LogToInspector('hidden layer: {0} | {1}'.Format([hiddenLayer[0], hiddenLayer[1]]));

        //forward hidden layer to output node
        for (define j = 0; j < CountOf(hiddenLayer); j++) {
            output += hiddenLayer[j] * w2[j];
            //LogToInspector('adding {0} * {1} to output'.Format([hiddenLayer[j], w2[j]]));
        }

        outputs = outputs.Append(output);
        //LogToInspector('----');
        //if (i == breakI1) {
            //Wait(0.016);
        //}
    }

    return outputs;
}

Number tanh(define x) 
{
    define e2x = RaiseToPower(e, 2*x);
    return (e2x - 1) / (e2x + 1);
    return x;
}

Number tanhDerivative(define x) {
    define y = tanh(x);
    return 1 - (y * y);
}

void backPropagate(define inputs, define actualValue) 'Back-propagation'
{
    Wait(0.016);
    define loss = feedForward(inputs) - actualValue;
    LogToInspector("Back-propagating...");
    define hlLosses = [];
    for (define i = 0; i < CountOf(w2); i++) {
        hlLosses = Append(hlLosses, w2[i] * loss * tanhDerivative(lastLayer1[i]));
        w2[i] = w2[i] - (learningRate * lastLayer1[i] * loss);
    }
    Wait(0.016);

    for (define j = 0; j < CountOf(inputs); j++) {
        define weights = w1[j];
        for (define i = 0; i < CountOf(hlLosses); i++) {
            weights[i] = weights[i] - (learningRate * inputs[j] * hlLosses[i]);
        }
        w1[j] = weights;
    }
}
//NEURAL NETWORK ENDS HERE
//==========================================================================

rule: 'Match Init'
{
    DisableInspectorRecording();
    //track server load
    CreateHudText(AllPlayers(), '{0} {1} {2}'.Format([ServerLoad(), ServerLoadAverage(), ServerLoadPeak()]),
    null, null, Location.Left, 1, Color.White, Color.Aqua, Color.Aqua, HudTextRev.VisibleToAndString, Spectators.VisibleAlways);
    //these two are crucial for performance - server crashes at regular speed, and
    //client crashes if inspector recording is enabled (too many step-throughs)
    
    //skip through game's setup phases, and setup array of players (excluding dummy). Wait times for extra stability
    Wait(15);
    players = [];
    for (define i = 1; i < 3; i++) {
        players = Append(players, PlayersInSlot(i, Team.Team1));
    }
    for (define i = 0; i < 3; i++) {
        players = Append(players, PlayersInSlot(i, Team.Team2));
    }
    SetMatchTime(0);
    Wait(5);
    SetMatchTime(0);
    Wait(18);
    SetSlowMotion(20);
    Wait(2);

    //spawn dummy next to slot 1 (teammate)
    CreateDummyBot(Hero.Soldier76, Team.Team1, 0, PlayersInSlot(1, Team.Team1));
}

rule: 'AI bot'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()))
{
    aiTime += 0.016;
    Wait(0.016);
    Loop();
}

rule: 'My Rule'
Event.OngoingPlayer
if (IsUsingAbility2(EventPlayer()))
{
    healingLocation = PositionOf(EventPlayer());
}

//get the health that could be recovered by ability
Number getRecoverableHealth(define position) {
    if (IsUsingAbility2() && DistanceBetween(healingLocation, position) < 4) {
        return (MaxHealth(EventPlayer()) - Health(EventPlayer())) / MaxHealth(EventPlayer());
    } else {
        return 0;
    }
}

enum BonusAction {
    None,
    Heal,
    Sprint,
    Ultimate
}

//returns an array [inputs, [extraInputs1, extraInputs2, etc.], targets, bonusActions]
//per teammate/enemy: distance, vertical distance, health, cooldown 1, 2, ult charge
//self: Health, ammo, cooldown rocket/heals, is using ultimate, potential healing?
//target: Health, distance, target hero thingy (5x bools)

//put extra input [targeting 1, 2, 3, 4, 5, sprinting, healthtogain, isusingultimate]
Number[] getInputs(define position) 'get inputs' {
    define inputs = [];
    define extraInputs = [];
    define targets = [];
    define bonusActions = [];
    //set inputs
    LogToInspector(1);
    inputs = Append(inputs, [Health(EventPlayer()) / MaxHealth(EventPlayer()),
                            Ammo(EventPlayer()) / MaxAmmo(EventPlayer()),
                            AbilityCooldown(EventPlayer(), Button.Ability2) / 18,
                            UltimateChargePercent(EventPlayer()) / 100,
                            DistanceBetween(position, EventPlayer()) / 30,
                            DistanceBetween(position, pfDestination) / 30,
                            DistanceBetween(ObjectivePosition(ObjectiveIndex()), EventPlayer())]);
    LogToInspector(1);
    for (define i = 0; i < CountOf(players); i++) {
        inputs = Append(inputs, [Health(players[i]) / MaxHealth(players[i]),
                                (IsAlive() && IsInLineOfSight(position, players[i], BarrierLOS.EnemyBarriersBlock)) ? 1 : -1,
                                DistanceBetween(position, players[i]) / 50,
                                DistanceBetween(position, players[i].positionTracking[0]) - DistanceBetween(position, players[i]) / 20,
                                Max(UltimateChargePercent(players[i]) / 100, IsUsingUltimate(players[i]))]);
    }
    LogToInspector(2);
    //sprinting to location
    extraInputs = Append(extraInputs, [[-1, -1, -1, 1, getRecoverableHealth(position), -1]]);
    targets = Append(targets, null);
    bonusActions = Append(bonusActions, BonusAction.Sprint);

    //heal
    if (AbilityCooldown(EventPlayer(), Button.Ability2) == 0) {
        extraInputs = Append(extraInputs, [[-1, -1, -1, -1, (MaxHealth(EventPlayer()) - Health(EventPlayer())) / MaxHealth(EventPlayer()), -1]]);
        targets = Append(targets, null);
        bonusActions = Append(bonusActions, BonusAction.Heal);
    }

    //use ult
    if (UltimateChargePercent(EventPlayer()) == 100) {
        extraInputs = Append(extraInputs, [[-1, -1, -1, -1, getRecoverableHealth(position), 1]]);
        targets = Append(targets, null);
        bonusActions = Append(bonusActions, BonusAction.Ultimate);
    }
    LogToInspector(3);

    //targeting each players in LOS
    define enemiesInRadius = PlayersWithinRadius(position, 50, Team.Team2, RadiusLOS.SurfacesAndEnemyBarriers);
    if (CountOf(enemiesInRadius) != 0) {
        for (define i = 0; i < CountOf(enemiesInRadius); i++) {
            define extraInput = [-1, -1, -1, -1, getRecoverableHealth(position), IsUsingUltimate(EventPlayer())];
            extraInput[SlotOf(enemiesInRadius[i])] = 1;
            extraInputs = Append(extraInputs, [extraInput]);
            targets = Append(targets, enemiesInRadius[i]);
            bonusActions = Append(bonusActions, BonusAction.None);
        }
    }
    LogToInspector(4);

    return [inputs, extraInputs, targets, bonusActions];
}

//adds numbers to array such that all values become non-negative.
//e.g. [-20, 40, -30, 60] becomes [10, 70, 0, 90]
Number[] numsToAllPositiveNums(define array) {
    define lowestNumber = 0;
    for (define i = 0; i < CountOf(array); i++) {
        lowestNumber = Min(lowestNumber, array[i]);
    }
    for (define i = 0; i < CountOf(array); i++) {
        array[i] = array[i] - lowestNumber;
    }
    return array;
}

Number sumArray(define array) {
    define sum = 0;
    for (define i = 0; i < CountOf(array); i++) {
        sum += array[i];
    }
    return sum;
}

rule: 'ai vars'
Event.OngoingPlayer
Player.Slot0
Team.Team1
{
    CreateHudText(AllPlayers(), "{0} {1} {2}".Format([probability, rand, whoops]));
    CreateHudText(AllPlayers(), "{0}".Format([oops]));
}
globalvar define oops = 0;
globalvar define whoops = 0;

playervar define probability;
playervar define rand;

rule: 'AI Loop'
Event.OngoingPlayer
Player.Slot0
Team.Team1
{
    Wait(1);
    while (TeamScore(Team.Team1) == 0 && TeamScore(Team.Team2) == 0) {
        if (IsAlive(EventPlayer())) {
            define choicePositions = [];
            define choiceTargets = [];
            define choiceInputs = [];
            define choiceValues = [];
            define choiceActions = [];

            //get the values of every possible state/action
            for (define i = -choiceMaxSteps; i <= choiceMaxSteps; i++) {
                for (define j = -choiceMaxSteps; j <= choiceMaxSteps; j++) {
                    define positions = [];
                    for (define k = -1; k <= 1; k++) {
                        define basePos = PositionOf(EventPlayer()) + Vector(i * choiceStepSize, k * 6, j * choiceStepSize);
                        define potentialPos = NearestWalkablePosition(basePos);
                        if (CountOf(positions) == 0) {
                            if (DistanceBetween(Vector(basePos.X, 0, basePos.Z),
                                                Vector(potentialPos.X, 0, potentialPos.Z)) < choiceStepSize) {
                                positions = Append(positions, potentialPos);
                            }
                        }  
                        else if (CountOf(positions) == 1) {
                            if (AbsoluteValue(YOf(positions[0]) - YOf(potentialPos)) >= 4) {
                                positions = Append(positions, potentialPos);
                            }
                        }
                        else if (CountOf(positions) == 2) {
                            if (AbsoluteValue(YOf(positions[0]) - YOf(potentialPos)) >= 4 && AbsoluteValue(YOf(positions[1]) - YOf(potentialPos)) >= 4) {
                                positions = Append(positions, potentialPos);
                            }
                        }
                    }
                    LogToInspector("got positions");
                    LogToInspector(CountOf(positions));

                    for (define posI = 0; posI < CountOf(positions); posI++) {
                        define input = getInputs(positions[posI]);
                        LogToInspector(CountOf(input));
                        LogToInspector("input");
                        define extraInputs = input[1];
                        define baseInput = input[0];
                        for (define k = 0; k < CountOf(input[1]); k++) {
                            choicePositions = Append(choicePositions, positions[posI]);
                            choiceInputs = Append(choiceInputs, [Append(baseInput, extraInputs[k])]);
                        }
                        choiceActions = Append(choiceActions, input[3]);
                        choiceTargets = Append(choiceTargets, input[2]);
                        LogToInspector("array stuff");
                        Wait(0.016);
                        define values = optimisedFeedForward(baseInput, extraInputs);
                        LogToInspector("feed-forward");
                        choiceValues = Append(choiceValues, values);
                        LogToInspector(posI);
                    }
                }
            }
            //get the index of the state-action to be chosen.
            define positiveValues = numsToAllPositiveNums(choiceValues);
            define sumValues = sumArray(positiveValues);
            probability = 0;
            rand = RandomReal(0.01, 0.99);
            define actionIndex = -1;
            //EnableInspectorRecording();
            while (probability <= rand && actionIndex < CountOf(positiveValues)) {
                actionIndex++;
                probability += positiveValues[actionIndex] / sumValues;
            }
            if (actionIndex == CountOf(positiveValues)) {
                oops += 1;
                EnableInspectorRecording();
                Wait(20);
            }

            Wait(0.016);

            handleBackprop(30);
            whoops = CountOf(pastInputRewards);
            
            //set enemy and position targets
            pfDestination = choicePositions[actionIndex];
            aimTarget = choiceTargets[actionIndex];
            extraAction = choiceActions[actionIndex];
            if (aimTarget != null) {
                StartFacing(EventPlayer(), DirectionTowards(EventPlayer(), aimTarget), 99, Relative.ToWorld, FacingRev.DirectionAndTurnRate);
            }
            else {
                StartFacing(EventPlayer(), DirectionTowards(EventPlayer(), pfWalkingToPosition), 99, Relative.ToWorld, FacingRev.DirectionAndTurnRate);
            }
            pastInputs = Append(pastInputs, [choiceInputs[actionIndex]]);
            pastInputTimes = Append(pastInputTimes, 0);
            pastInputRewards = Append(pastInputRewards, 0);
            //end rule, run again next tick
        }
        //else if death
        else {
            //backprop every input made leading up to death
            //EnableInspectorRecording();
            //Wait(20);
            pfDestination = null;
            handleBackprop(0);
            //WaitUntil(IsAlive(EventPlayer()), 20);
        }
        Wait(0.016);
    } 
    //else (meaning first round has finished, so the simulation should end)
    handleBackprop(0);
    finish();
}

void handleBackprop(define inputLifespan) 'Attribute reward and handle Backpropagation' {
    if (CountOf(pastInputs) > 0) {
        define indexesToRemove = [];

        //for each input
        for (define i = 0; i < CountOf(pastInputs); i++) {
            pastInputTimes[i] += deltaTime;

            //add reward to the input, where 0.9 is the discount rate
            pastInputRewards[i] += deltaReward * RaiseToPower(0.9, pastInputTimes[i]);

            //if the input was made more than inputLifespan secs ago, backpropagate using the value accumulated since then
            if (inputLifespan != -1 && pastInputTimes[i] >= inputLifespan) {
                backPropagate(pastInputs[i], pastInputRewards[i]);
                indexesToRemove = Append(indexesToRemove, i);
                Wait(0.016);
            }
        }

        //remove the backpropagated inputs
        for (define i = 0; i < CountOf(indexesToRemove); i++) {
            pastInputs = RemoveFromArrayAtIndex(pastInputs, indexesToRemove[i]);
            pastInputTimes = RemoveFromArrayAtIndex(pastInputTimes, indexesToRemove[i]);
            pastInputRewards = RemoveFromArrayAtIndex(pastInputRewards, indexesToRemove[i]);
        }

        Wait(0.016);

        deltaTime = 0;
        deltaReward = 0;
    }
}

void finish() 'Log results at end of match'
{
    SetSlowMotion(10);
    EnableInspectorRecording();
    define aiSoldier = PlayersOnHero(Hero.Soldier76, Team.Team1)[0];
    define enemySoldier = PlayersOnHero(Hero.Soldier76, Team.Team2)[0];

    LogToInspector('Match time (seconds): {0}'.Format([aiTime]));
    LogToInspector('stats formatted as: damage/heals/kills/deaths/ultimatedmg/rocketdmg');
    LogToInspector('AI stats: {0}, {1}, {2}, {3}, {4}, {5}'.Format([
        aiSoldier.dmgDealtStat, aiSoldier.healingStat, aiSoldier.eliminationStat, 
        aiSoldier.deathStat, aiSoldier.ultimateDmgStat, aiSoldier.rocketDmgStat
    ]));
    LogToInspector('Enemy stats: {0}, {1}, {2}, {3}, {4}, {5}'.Format([
        enemySoldier.dmgDealtStat, enemySoldier.healingStat, enemySoldier.eliminationStat, 
        enemySoldier.deathStat, enemySoldier.ultimateDmgStat, enemySoldier.rocketDmgStat
    ]));
    //check the stats recorded for enemy soldier against the official stat-tracking.
    //dummy bot stats are not recorded via these methods, neccessitating the custom tracking
    LogToInspector('Enemy assurance stats: {0} {1} {2} {3} {4}'.Format([PlayerHeroStat(enemySoldier, Hero.Soldier76, PlayerHeroStat.AllDamageDealt),
                                                                    PlayerHeroStat(enemySoldier, Hero.Soldier76, PlayerHeroStat.HealingDealt),
                                                                    PlayerHeroStat(enemySoldier, Hero.Soldier76, PlayerHeroStat.Eliminations),
                                                                    PlayerHeroStat(enemySoldier, Hero.Soldier76, PlayerHeroStat.Deaths),
                                                                    PlayerHeroStat(enemySoldier, Hero.Soldier76, PlayerHeroStat.WeaponAccuracy)]));
    Wait(0.016);
    LogToInspector("Team 1 Win: {0}".Format([TeamScore(Team.Team1)]));
    LogToInspector("Team 1 Score: {0}".Format([team1Score]));
    LogToInspector("Team 2 Win: {0}".Format([TeamScore(Team.Team2)]));
    LogToInspector("Team 2 Score: {0}".Format([team2Score]));
    DestroyAllDummyBots();
    //Prepare vars for export/import
    w1Import1 = [];
    w1Import2 = [];
    w1Import3 = [];
    w2Import = [];
    //PLEASE ADJUST FOR ACTUAL NODE/WEIGHT COUNT AS NECESSARY
    for (define i = 0; i < 38; i++)  {
        w1Import1 = Append(w1Import1, [w1[i]]);
    }
    Wait(0.016);
    for (define i = 40; i < 63; i++)  {
        w1Import2 = Append(w1Import1, [w1[i]]);
    }
    Wait(0.016);
    for (define i = 80; i < 81; i++) {
        //w1Import3 = Append(w1Import3, [w1[i]]);
    }
    w2Import = w2;

    Wait(10);
    SetMatchTime(999);
}

rule: 'Bot start shooting'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()) && aimTarget != null && IsInLineOfSight(EventPlayer(), aimTarget, BarrierLOS.EnemyBarriersBlock))
{
    StopHoldingButton(EventPlayer(), Button.Ability1);
    StartHoldingButton(EventPlayer(), Button.PrimaryFire);
}

rule: 'Bot stop shooting'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()) && (aimTarget == null || !IsInLineOfSight(EventPlayer(), aimTarget, BarrierLOS.EnemyBarriersBlock)))
{
    StopHoldingButton(EventPlayer(), Button.PrimaryFire);
    StartHoldingButton(EventPlayer(), Button.Ability1);
}

rule: 'Bot use heals'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()) && extraAction == BonusAction.Heal)
{
    WaitUntil(DistanceBetween(EventPlayer(), pfDestination) < 4, 0.5);
    PressButton(EventPlayer(), Button.Ability2);
}

rule: 'Bot use ult'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()) && extraAction == BonusAction.Ultimate)
{
    WaitUntil(DistanceBetween(EventPlayer(), pfDestination) < 4, 0.5); 
    PressButton(EventPlayer(), Button.Ultimate);
}

rule: 'Bot fire rocket'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()) && aimTarget != null && IsInLineOfSight(EventPlayer(), aimTarget, BarrierLOS.EnemyBarriersBlock) && AbilityCooldown(EventPlayer(), Button.SecondaryFire) == 0)
{
    PressButton(EventPlayer(), Button.SecondaryFire);
}

rule: 'track damage'
Event.OnDamageDealt
Player.Soldier76
{
    if (EventAbility() == Button.PrimaryFire) {
        dmgDealtStat += EventDamage();
    }
    else if (EventAbility() == Button.SecondaryFire) {
        rocketDmgStat += EventDamage() / (dmgPercent / 100);
    }
    else if (EventAbility() == Button.Ultimate) {
        ultimateDmgStat += EventDamage();
    }
}

rule: 'track heal'
Event.OnHealingDealt
Player.Soldier76
{
    healingStat += EventHealing();
    deltaReward += EventHealing() * 0.005;
}
rule: 'track elim'
Event.OnElimination
Player.Soldier76
{
    eliminationStat += 1;
}
rule: 'track death'
Event.OnDeath
Player.Soldier76
{
    deathStat += 1;
}

//explaining the next 3 rules:
//The AI has near-perfect aim with primary fire. 
//To offset this, the damage dealt outside of its ultimate (which intentionally gives it perfect aim) is lowered to dmgPercent.
//When other abilities (e.g., rocket) hits, the AI's aim is imperfect, so extra damage is dealt to bring the damage dealt back up.
rule: 'AI dmg adjust for ult'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()) && IsUsingUltimate(EventPlayer()))
{
    SetDamageDealt(EventPlayer(), 100);
}

rule: 'AI dmg adjust for non-ult'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()) && !IsUsingUltimate(EventPlayer()))
{
    SetDamageDealt(EventPlayer(), dmgPercent);
}

rule: 'AI deal extra damage to offset nerf'
Event.OnDamageDealt
if (IsDummyBot(EventPlayer()) && EventAbility() == Button.SecondaryFire && dmgPercent != 100)
{
    Damage(Victim(), EventPlayer(), EventDamage() / (dmgPercent / 100));
}

rule: 'deltaTime update'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()))
{
    deltaTime += 0.016;
    Wait(0.016);
    Loop();
}

rule: 'Reward damage'
Event.OnDamageDealt
Player.Slot0
Team.Team1
{
    deltaReward += EventDamage() * 0.01;
}

rule: 'Reward point lost'
Player.Slot0
Team.Team1
if (ControlModeScoringTeam() == Team.Team2)
{
    deltaReward -= 2.5;
}

rule: 'Reward point taken'
Player.Slot0
Team.Team1
if (ControlModeScoringTeam() == Team.Team1)
{
    deltaReward += 2.5;
}

rule: 'Reward kill'
Event.OnElimination
Player.Slot0
Team.Team1
{
    deltaReward += 2;
}

rule: 'Reward damage'
Event.OnDamageTaken
Player.Slot0
Team.Team1
{
    deltaReward -= EventDamage() * 0.01;
}

rule: 'Reward damage'
Event.OnDeath
Player.Slot0
Team.Team1
{
    deltaReward -= EventDamage() * 0.01;
}

rule: 'track positioning'
Event.OngoingPlayer
{
    positionTracking = Append(positionTracking, PositionOf(EventPlayer()));
    if (CountOf(positionTracking) > 15) {
        ModifyVariable(positionTracking, Operation.RemoveFromArrayByIndex, 0);
    }
    Wait(0.2);
    Loop();
}

rule: 'Update scores'
{
    if (MatchRound() < 2) {
        team1Score = ControlModeScoringPercentage(Team.Team1);
        team2Score = ControlModeScoringPercentage(Team.Team2);
    }
    Wait(1);
    Loop();
}