//This is the main file - you'll want to compile using this file (it imports every other one).

import 'pathfinder.del';

globalvar define e = 2.718281828;
playervar define deltaReward = 0;
globalvar define choiceMaxSteps = 3;
globalvar define choiceStepSize = 6;
globalvar define deltaTime = 0;
globalvar define pastInputs = [];
globalvar define pastInputTimes = [];
globalvar define pastInputRewards = [];
globalvar define aiTime = 0;
playervar define aimTarget = null;
playervar define extraAction = null;
playervar define positionTracking = [];
playervar define dmgPercent; //dmg multiplier (in percent) for primary fire (compensating for near-perfect aim)
rule: 'assignDmgPercent'
Event.OngoingPlayer
{
    if (IsDummyBot(EventPlayer())) {
        dmgPercent = 30;
    } else {
        dmgPercent = 100;
    }
}

globalvar define players = [];
playervar define dmgDealtStat = 0;
playervar define healingStat = 0;
playervar define eliminationStat = 0;
playervar define deathStat = 0;
playervar define rocketDmgStat = 0;
playervar define ultimateDmgStat = 0;
playervar define healingLocation;

globalvar define w1Import1;
globalvar define w1Import2;
globalvar define w1Import3;
globalvar define w2Import;

rule: '>>> Import Weights Part 1 (paste them here!) <<<'
{
    
}

rule: '>>> Import Weights Part 2 (paste them here!) <<<'
{
    
}

rule: '>>> Import Weights Part 3 (paste them here!) <<<'
{
    
}

rule: 'init weights'
{
    Wait(5);
    w1 = [];
    w2 = [];
    if (w1Import1 != null && w1Import2 != null && w2Import != null) {
        w1 = Append(w1, w1Import1);
        w1 = Append(w1, w1Import2);
        w1 = Append(w1, w1Import3);
        w2 = w2Import;
    }
    else {
        //PLEASE ADJUST FOR ACTUAL NODE/WEIGHT COUNT AS NECESSARY
        for (define i! = 0; i < 99; i++) {
            define array = [];
            for (define j! = 0; j < 66; j++) {
                array = Append(array, RandomReal(-1, 1));
            }   
            w1 = Append(w1, [array]);
            Wait(0.016);
        }

        for (define i! = 0; i < 66; i++) {
            w2 = Append(w2, RandomReal(-1, 1));
        }
    }
}



//===============================================================================================================
//NEURAL NETWORK BEGINS HERE
//this could be bundled into a class, but classes are merely an abstraction that place their instance's vars into a shared array
//this effectively makes the weights a 3d array, which would kill performance
globalvar define learningRate = 0.1;
globalvar define w1;
globalvar define w2;   
globalvar define lastLayer1;

Number feedForward(define inputs) 'test'
{
    LogToInspector("Feeding forward...");
    define output = 0;
    define layer1 = [];

    //forward all inputs to hidden layer. w2 has one weight per HL node, so it's used for the countof
    for (define i! = 0; i < CountOf(w2); i++) {
        for (define j! = 0; j < CountOf(inputs); j++) {
            layer1[i] += inputs[j] * w1[j][i];
            //LogToInspector(w1[j][i]);
        }
    }
    //LogToInspector(layer1);

    //activation function on hidden layer
    for (define i! = 0; i < CountOf(w2); i++) {
        layer1[i] = tanh(layer1[i]);
    } 

    //LogToInspector(layer1);

    //forward hidden layer to output node
    for (define i! = 0; i < CountOf(w2); i++) {
        output += layer1[i] * w2[i];
    }

    lastLayer1 = layer1;

    return output;
}

//feedforward optimised for multiple FFs. calculates the non-activated values for the first hidden layer once,
//then reuses them for each FF, adding on inputs from extraInputs[i] each time.
//this reduces the multiplications needed for subsequent FFs, saving server resources
define optimisedFeedForward(define inputs, define extraInputs) {
    define layer1 = [];
    define baseWeightI = 0;

    for (define i! = 0; i < CountOf(w2); i++) {
        for (define j = 0; j < CountOf(inputs); j++) {
            layer1[i] += inputs[j] * w1[j][i];
            baseWeightI = j;
        }
    }

    //LogToInspector("i {0}".Format([baseWeightI]));

    define outputs = [];
    LogToInspector('the layers');
    for (define i! = 0; i < CountOf(extraInputs); i++) {
        define output = 0;
        define hiddenLayer = layer1;
        for (define j = 0; j < CountOf(hiddenLayer); j++) {
            for (define k = 0; k < CountOf(extraInputs[i]); k++) {
                hiddenLayer[j] += extraInputs[i][k] * w1[baseWeightI + 1 + k][j];
                //LogToInspector('multiplying {0} by {1}'.Format([extraInputs[i][k], w1[baseWeightI + 1 + k][j]]));
            }
        }

        for (define j! = 0; j < CountOf(layer1); j++) {
            hiddenLayer[j] = tanh(hiddenLayer[j]);
        } 

        //LogToInspector('hidden layer: {0} | {1}'.Format([hiddenLayer[0], hiddenLayer[1]]));

        //forward hidden layer to output node
        for (define j! = 0; j < CountOf(hiddenLayer); j++) {
            output += hiddenLayer[j] * w2[j];
            //LogToInspector('adding {0} * {1} to output'.Format([hiddenLayer[j], w2[j]]));
        }

        outputs = outputs.Append(output);
        //LogToInspector('----');
    }

    return outputs;
}

Number tanh(define x) 
{
    define e2x = RaiseToPower(e, 2*x);
    return (e2x - 1) / (e2x + 1);
}

Number tanhDerivative(define x) {
    return 1 - RaiseToPower(tanh(x), 2);
}

void backPropagate(define inputs, define actualValue) 'Back-propagation'
{
    define loss = feedForward(inputs) - actualValue;
    Wait(0.016);
    LogToInspector("Back-propagating...");
    define hlLosses = [];
    for (define i = 0; i < CountOf(w2); i++) {
        hlLosses = Append(hlLosses, w2[i] * loss * tanhDerivative(lastLayer1[i]));
        w2[i] = w2[i] - (learningRate * lastLayer1[i] * loss);
    }

    for (define i = 0; i < CountOf(hlLosses); i++) {
        for (define j = 0; j < CountOf(inputs); j++) {
            w1[j][i] = w1[j][i] - (learningRate * inputs[j][i] * hlLosses[i]);
        }
    }
}
//NEURAL NETWORK ENDS HERE
//==========================================================================

rule: 'Match Init'
{
    //track server load
    CreateHudText(AllPlayers(), '{0} {1} {2}'.Format([ServerLoad(), ServerLoadAverage(), ServerLoadPeak()]),
    null, null, Location.Left, 1, Color.White, Color.Aqua, Color.Aqua, HudTextRev.VisibleToAndString, Spectators.VisibleAlways);
    //these two are crucial for performance - server crashes at regular speed, and
    //client crashes if inspector recording is enabled (too many step-throughs)
    SetSlowMotion(20);
    DisableInspectorRecording();
    
    //skip through game's setup phases, and setup array of players (excluding dummy). Wait times for extra stability
    Wait(5);
    players = [];
    for (define i = 1; i < 5; i++) {
        players = Append(players, PlayersInSlot(i, Team.Team1));
    }
    for (define i = 0; i < 5; i++) {
        players = Append(players, PlayersInSlot(i, Team.Team2));
    }
    SetMatchTime(0);
    Wait(5);
    SetMatchTime(0);

    //spawn dummy next to slot 1 (teammate)
    CreateDummyBot(Hero.Soldier76, Team.Team1, 0, PlayersInSlot(1, Team.Team1));
}

rule: 'AI bot'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()))
{
    aiTime += 0.016;
    Wait(0.016);
    Loop();
}

rule: 'AI Init'
Player.Slot0
Team.Team1
{

}


rule: 'AI Test'
Player.Slot0
Team.Team1
{
    w1 = [[0.3, 0.8], [0.6, -0.7], [-0.4, -0.5]];
    w2 = [-0.3, 0.2];
    LogToInspector(feedForward([0.36, -1, 0.4]));
    LogToInspector(optimisedFeedForward([0.36, -1], [[0.4]]));
    define sus = optimisedFeedForward([0.36], [[-1, 0.4], [0.8, -0.11], [-1, 0.4]]);
    LogToInspector('the susses');
    LogToInspector(sus[0]);
    LogToInspector(sus[1]);
    LogToInspector(sus[2]);
    backPropagate([0.36, -1, 0.4], -5);
    LogToInspector(feedForward([0.36, -1, 0.4]));
    LogToInspector(optimisedFeedForward([0.36, -1], [[0.4]]));
}

rule: 'My Rule'
Event.OngoingPlayer
if (IsUsingAbility2(EventPlayer()))
{
    healingLocation = PositionOf(EventPlayer());
}

//get the health that could be recovered by ability
Number getRecoverableHealth(define position) {
    if (IsUsingAbility2() && DistanceBetween(healingLocation, position) < 4) {
        return (MaxHealth(EventPlayer()) - Health(EventPlayer())) / MaxHealth(EventPlayer());
    } else {
        return 0;
    }
}

enum BonusAction {
    None,
    Heal,
    Sprint,
    Ultimate
}

//returns an array [inputs, [extraInputs1, extraInputs2, etc.], targets, bonusActions]
//per teammate/enemy: distance, vertical distance, health, cooldown 1, 2, ult charge
//self: Health, ammo, cooldown rocket/heals, is using ultimate, potential healing?
//target: Health, distance, target hero thingy (5x bools)

//put extra input [targeting 1, 2, 3, 4, 5, sprinting, healthtogain, isusingultimate]
Number[] getInputs(define position) {
    define inputs = [];
    define extraInputs = [];
    define targets = [];
    define bonusActions = [];
    //set inputs
    inputs = Append(inputs, [Health(EventPlayer()) / MaxHealth(EventPlayer()),
                            Ammo(EventPlayer()) / MaxAmmo(EventPlayer()),
                            AbilityCooldown(EventPlayer(), Button.Ability2) / 18,
                            UltimateChargePercent(EventPlayer()) / 100,
                            DistanceBetween(position, EventPlayer()) / 30,
                            DistanceBetween(position, pfDestination) / 30,
                            DistanceBetween(ObjectivePosition(ObjectiveIndex()), EventPlayer()),
                            YOf(position) - YOf(ObjectivePosition(ObjectiveIndex())) / 10,
                            CurrentMap() == Map.Samoa ? 1 : -1,
                            CurrentMap() == Map.Busan ? 1 : -1]);
    for (define i! = 0; i < CountOf(players); i++) {
        inputs = Append(inputs, [Health(players[i]) / MaxHealth(players[i]),
                                IsInLineOfSight(position, players[i], BarrierLOS.EnemyBarriersBlock) ? 1 : -1,
                                DistanceBetween(position, players[i]) / 50,
                                DistanceBetween(position, players[i].positionTracking[0]) - DistanceBetween(position, players[i]) / 20,
                                AbsoluteValue(HorizontalAngleTowards(players[i], position)) / 180,
                                YOf(position) - YOf(PositionOf(players[i])) / 10,
                                AbilityCooldown(players[i], Button.Ability1) / 10,
                                AbilityCooldown(players[i], Button.Ability2) / 10,
                                Max(UltimateChargePercent(players[i]) / 100, IsUsingUltimate(players[i]))]);
    }
    //sprinting to location
    extraInputs = Append(extraInputs, [[-1, -1, -1, -1, -1, 1, getRecoverableHealth(position), -1]]);
    targets = Append(targets, null);
    bonusActions = Append(bonusActions, BonusAction.Sprint);

    //heal
    if (AbilityCooldown(EventPlayer(), Button.Ability2) == 0) {
        extraInputs = Append(extraInputs, [[-1, -1, -1, -1, -1, -1, (MaxHealth(EventPlayer()) - Health(EventPlayer())) / MaxHealth(EventPlayer()), -1]]);
        targets = Append(targets, null);
        bonusActions = Append(bonusActions, BonusAction.Heal);
    }

    //use ult
    if (UltimateChargePercent(EventPlayer()) == 100) {
        extraInputs = Append(extraInputs, [[-1, -1, -1, -1, -1, -1, getRecoverableHealth(position), 1]]);
        targets = Append(targets, null);
        bonusActions = Append(bonusActions, BonusAction.Ultimate);
    }

    //targeting each players in LOS
    define enemiesInRadius = PlayersWithinRadius(position, 50, Team.Team2, RadiusLOS.SurfacesAndEnemyBarriers);
    for (define i! = 0; i < enemiesInRadius; i++) {
        define extraInput = [-1, -1, -1, -1, -1, -1, getRecoverableHealth(position), IsUsingUltimate(EventPlayer())];
        extraInput[SlotOf(enemiesInRadius[i])] = 1;
        extraInputs = Append(extraInputs, [extraInput]);
        targets = Append(targets, enemiesInRadius[i]);
        bonusActions = Append(bonusActions, BonusAction.None);
    }

    return [inputs, extraInputs, targets, bonusActions];
}

//adds numbers to array such that all values become non-negative.
//e.g. [-20, 40, -30, 60] becomes [10, 70, 0, 90]
Number[] numsToAllPositiveNums(define array) {
    define lowestNumber = 0;
    for (define i! = 0; i < CountOf(array); i++) {
        lowestNumber = Min(lowestNumber, array[i]);
    }
    for (define i! = 0; i < CountOf(array); i++) {
        array[i] = array[i] - lowestNumber;
    }
    return array;
}

Number sumArray(define array) {
    define sum = 0;
    for (define i! = 0; i < CountOf(array); i++) {
        sum += array[i];
    }
    return sum;
}

rule: 'AI Loop'
Event.OngoingPlayer
Player.Slot0
Team.Team1
if (false)
{
    if (MatchRound() < 2 && IsAlive(EventPlayer())) {
        define choicePositions = [];
        define choiceTargets = [];
        define choiceInputs = [];
        define choiceValues = [];
        define choiceActions = [];

        //get the values of every possible state/action
        for (define i! = -choiceMaxSteps; i <= choiceMaxSteps; i++) {
            for (define j! = -choiceMaxSteps; j <= choiceMaxSteps; j++) {
                define positions = [];
                for (define k! = -1; k <= 1; k++) {
                    define basePos = PositionOf(EventPlayer()) + Vector(i * choiceStepSize, k * 6, j * choiceStepSize);
                    define potentialPos = NearestWalkablePosition(basePos);
                    if (CountOf(positions) == 0) {
                        if (DistanceBetween(Vector(basePos.X, 0, basePos.Z),
                                            Vector(potentialPos.X, 0, potentialPos.Z)) < choiceStepSize) {
                            positions = Append(positions, potentialPos);
                        }
                    }  
                    else if (CountOf(positions) == 1) {
                        if (AbsoluteValue(YOf(positions[0]) - YOf(potentialPos)) >= 4) {
                            positions = Append(positions, potentialPos);
                        }
                    }
                    else if (CountOf(positions) == 2) {
                        if (AbsoluteValue(YOf(positions[0]) - YOf(potentialPos)) >= 4 && AbsoluteValue(YOf(positions[1]) - YOf(potentialPos)) >= 4) {
                            positions = Append(positions, potentialPos);
                        }
                    }
                }

                for (define posI! = 0; posI < CountOf(positions); posI++) {
                    define input = getInputs(positions[posI]);
                    for (define k = 0; k < CountOf(input[1]); k++) {
                        choicePositions = Append(choicePositions, positions[posI]);
                        choiceInputs = Append(choiceInputs, Append(input[0], input[1][k]));
                    }
                    choiceActions = Append(choiceActions, input[3]);
                    choiceTargets = Append(choiceTargets, input[2]);
                    define extraInputs = input[1];
                    input = input[0];
                    define values = optimisedFeedForward(input, extraInputs);
                    choiceValues = Append(choiceValues, [values]);
                    Wait(0.016);
                }
            }
        }

        //get the index of the state-action to be chosen.
        define positiveValues = numsToAllPositiveNums(choiceValues);
        define sumValues = sumArray(positiveValues);
        define probability = 0;
        define rand = RandomReal(0, 1);
        define actionIndex = -1;
        while (probability < rand) {
            actionIndex++;
            probability += positiveValues[actionIndex] / sumValues;
        }
        Wait(0.016);

        handleBackprop(30);
        
        //set enemy and position targets
        pfDestination = choicePositions[actionIndex];
        aimTarget = choiceTargets[actionIndex];
        extraAction = choiceActions[actionIndex];
        if (aimTarget != null) {
            StartFacing(EventPlayer(), aimTarget, 5, Relative.ToWorld, FacingRev.None);
        }
        else {
            StartFacing(EventPlayer(), ThrottleOf(EventPlayer()), 5, Relative.ToWorld, FacingRev.DirectionAndTurnRate);
        }

        pastInputs = Append(pastInputs, choiceInputs[actionIndex]);
        pastInputTimes = Append(pastInputTimes, 0);
        pastInputRewards = Append(pastInputRewards, 0);
        //end rule, run again next tick
        Wait(0.016);
        Loop();
    } 
    //else if death
    else if (MatchRound() < 2 && !IsAlive(EventPlayer())) {
        //backprop every input made leading up to death
        handleBackprop(0);
    }
    //else (meaning first round has finished, so the simulation should end)
    else {
        handleBackprop(0);
        finish();
    }
}

void handleBackprop(define inputLifespan) 'Attribute reward and handle Backpropagation' {
    if (CountOf(pastInputs) > 0) {
        define indexesToRemove = [];

        //for each input
        for (define i! = 0; i < CountOf(pastInputs); i++) {
            pastInputTimes[i] += deltaTime;

            //add reward to the input, where 0.9 is the discount rate
            pastInputRewards[i] += deltaReward * RaiseToPower(0.9, pastInputTimes[i]);

            //if the input was made more than inputLifespan secs ago, backpropagate using the value accumulated since then
            if (pastInputTimes[i] >= inputLifespan) {
                backPropagate(pastInputs[i], pastInputRewards[i]);
                indexesToRemove = Append(indexesToRemove, i);
                Wait(0.016);
            }
        }

        //remove the backpropagated inputs
        for (define i! = 0; i < CountOf(indexesToRemove); i++) {
            pastInputs = RemoveFromArrayAtIndex(pastInputs, indexesToRemove[i]);
            pastInputTimes = RemoveFromArrayAtIndex(pastInputTimes, indexesToRemove[i]);
            pastInputRewards = RemoveFromArrayAtIndex(pastInputRewards, indexesToRemove[i]);
        }

        deltaTime = 0;
        deltaReward = 0;
    }
}



void finish() 'Log results at end of match'
{
    //Prepare vars for export/import
    w1Import1 = [];
    w1Import2 = [];
    w1Import3 = [];
    w2Import = [];
    //PLEASE ADJUST FOR ACTUAL NODE/WEIGHT COUNT AS NECESSARY
    for (define i! = 0; i < 40; i++)  {
        w1Import1 = Append(w1Import1, [w1[i]]);
    }
    for (define i! = 40; i < 80; i++)  {
        w1Import2 = Append(w1Import1, [w1[i]]);
    }
    Wait(0.016);
    for (define i! = 80; i < 99; i++) {
        w1Import3 = Append(w1Import3, [w1[i]]);
    }
    w2Import = w2;

    define aiSoldier = PlayersOnHero(Hero.Soldier76, Team.Team1)[0];
    define enemySoldier = PlayersOnHero(Hero.Soldier76, Team.Team2)[0];

    LogToInspector('Match time (seconds): {0}'.Format([aiTime]));
    LogToInspector('stats formatted as: damage/heals/kills/deaths/ultimatedmg/rocketdmg');
    LogToInspector('AI stats: {0}, {1}, {2}, {3}, {4}, {5}'.Format([
        aiSoldier.dmgDealtStat, aiSoldier.healingStat, aiSoldier.eliminationStat, 
        aiSoldier.deathStat, aiSoldier.ultimateDmgStat, aiSoldier.rocketDmgStat
    ]));
    LogToInspector('Enemy stats: {0}, {1}, {2}, {3}, {4}, {5}'.Format([
        enemySoldier.dmgDealtStat, enemySoldier.healingStat, enemySoldier.eliminationStat, 
        enemySoldier.deathStat, enemySoldier.ultimateDmgStat, enemySoldier.rocketDmgStat
    ]));
    //check the stats recorded for enemy soldier against the official stat-tracking.
    //dummy bot stats are not recorded via these methods, neccessitating the custom tracking
    LogToInspector('Enemy assurance stats: {0} {1} {2} {3}'.Format([PlayerHeroStat(enemySoldier, Hero.Soldier76, PlayerHeroStat.AllDamageDealt),
                                                                    PlayerHeroStat(enemySoldier, Hero.Soldier76, PlayerHeroStat.HealingDealt),
                                                                    PlayerHeroStat(enemySoldier, Hero.Soldier76, PlayerHeroStat.Eliminations),
                                                                    PlayerHeroStat(enemySoldier, Hero.Soldier76, PlayerHeroStat.Deaths)]));
    LogToInspector("Team 1 score: {0}".Format([TeamScore(Team.Team1)]));
    LogToInspector("Team 2 score: {0}".Format([TeamScore(Team.Team2)]));
    DestroyAllDummyBots();
    EnableInspectorRecording();
    Wait(10);
    SetMatchTime(999);
    SetSlowMotion(10);
}

rule: 'Bot start shooting'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()) && aimTarget != null && IsInLineOfSight(EventPlayer(), aimTarget, BarrierLOS.EnemyBarriersBlock))
{
    StopHoldingButton(EventPlayer(), Button.Ability1);
    StartHoldingButton(EventPlayer(), Button.PrimaryFire);
}

rule: 'Bot stop shooting'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()) && aimTarget == null)
{
    StopHoldingButton(EventPlayer(), Button.PrimaryFire);
    StartHoldingButton(EventPlayer(), Button.Ability1);
}

rule: 'Bot use heals'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()) && extraAction == BonusAction.Heal)
{
    WaitUntil(DistanceBetween(EventPlayer(), pfDestination) < 4, 0.5);
    PressButton(EventPlayer(), Button.Ability2);
}

rule: 'Bot use ult'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()) && extraAction == BonusAction.Ultimate)
{
    WaitUntil(DistanceBetween(EventPlayer(), pfDestination) < 4, 0.5); 
    PressButton(EventPlayer(), Button.Ultimate);
}

rule: 'Bot fire rocket'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()) && aimTarget != null && IsInLineOfSight(EventPlayer(), aimTarget, BarrierLOS.EnemyBarriersBlock) && AbilityCooldown(EventPlayer(), Button.SecondaryFire) == 0)
{
    PressButton(EventPlayer(), Button.SecondaryFire);
}

rule: 'track damage'
Event.OnDamageDealt
Player.Soldier76
{
    if (EventAbility() == Button.PrimaryFire) {
        dmgDealtStat += EventDamage();
    }
    else if (EventAbility() == Button.SecondaryFire) {
        rocketDmgStat += EventDamage() / (dmgPercent / 100);
    }
    else if (EventAbility() == Button.Ultimate) {
        ultimateDmgStat += EventDamage();
    }
}

rule: 'track heal'
Event.OnHealingDealt
Player.Soldier76
{
    healingStat += EventHealing();
}
rule: 'track elim'
Event.OnElimination
Player.Soldier76
{
    eliminationStat += 1;
}
rule: 'track death'
Event.OnDeath
Player.Soldier76
{
    deathStat += 1;
}

//explaining the next 3 rules:
//The AI has near-perfect aim with primary fire. 
//To offset this, the damage dealt outside of its ultimate (which intentionally gives it perfect aim) is lowered to dmgPercent.
//When other abilities (e.g., rocket) hits, the AI's aim is imperfect, so extra damage is dealt to bring the damage dealt back up.
rule: 'AI dmg adjust for ult'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()) && IsUsingUltimate(EventPlayer()))
{
    SetDamageDealt(EventPlayer(), 100);
}

rule: 'AI dmg adjust for non-ult'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()) && !IsUsingUltimate(EventPlayer()))
{
    SetDamageDealt(EventPlayer(), dmgPercent);
}

rule: 'AI deal extra damage to offset nerf'
Event.OnDamageDealt
if (IsDummyBot(EventPlayer()) && EventAbility() == Button.SecondaryFire && dmgPercent != 100)
{
    Damage(Victim(), EventPlayer(), EventDamage() / (dmgPercent / 100));
}

rule: 'deltaTime update'
Event.OngoingPlayer
if (IsDummyBot(EventPlayer()))
{
    deltaTime += 0.016;
    Wait(0.016);
    Loop();
}

rule: 'Reward damage'
Event.OnDamageDealt
Player.Slot0
Team.Team1
{
    deltaReward += EventDamage();
}

rule: 'Reward point lost'
Player.Slot0
Team.Team1
if (ControlModeScoringTeam() == Team.Team2)
{
    deltaReward -= 100;
}

rule: 'Reward point taken'
Player.Slot0
Team.Team1
if (ControlModeScoringTeam() == Team.Team1)
{
    deltaReward += 100;
}

rule: 'Reward kill'
Event.OnElimination
Player.Slot0
Team.Team1
{
    deltaReward += 200;
}

rule: 'Reward damage'
Event.OnDamageTaken
Player.Slot0
Team.Team1
{
    deltaReward -= EventDamage();
}

rule: 'Reward damage'
Event.OnDeath
Player.Slot0
Team.Team1
{
    deltaReward -= EventDamage();
}

rule: 'place heals'
Event.OngoingPlayer
if (Health(EventPlayer()) < 150 && AbilityCooldown(EventPlayer(), Button.Ability2) == 0)
{
    PressButton(EventPlayer(), Button.Ability2);
}

rule: 'track positioning'
Event.OngoingPlayer
{
    positionTracking = Append(positionTracking, PositionOf(EventPlayer()));
    if (CountOf(positionTracking) > 15) {
        ModifyVariable(positionTracking, Operation.RemoveFromArrayByIndex, 0);
    }
    Wait(0.2);
    Loop();
}